"""
Communication monitoring with Pandas - Clean version
"""

import reflex as rx
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from ksys_app.db import q


class CommunicationState(rx.State):
    """Pandas ê¸°ë°˜ í†µì‹  ëª¨ë‹ˆí„°ë§ ìƒíƒœ ê´€ë¦¬"""
    
    # UI Controls
    selected_tag: str = "D100"
    selected_days: int = 7
    loading: bool = False
    
    # Data Storage (ë‚´ë¶€ìš©)
    available_tags: List[str] = []
    _df_hourly: List[Dict] = []  # DataFrameì„ dict listë¡œ ì €ì¥
    _df_daily: List[Dict] = []
    
    @rx.var
    def selected_days_str(self) -> str:
        """Radio groupìš© ë¬¸ìì—´ ë³€í™˜"""
        return str(self.selected_days)
    
    @rx.var
    def active_hours_str(self) -> str:
        """í™œì„± ì‹œê°„ ìˆ˜"""
        return str(len(self._df_hourly))
    
    @rx.var
    def total_hours_str(self) -> str:
        """ì „ì²´ ì‹œê°„ ë¼ë²¨"""
        return f"Out of {self.selected_days * 24} hours"
    
    @rx.var
    def overall_success_rate(self) -> float:
        """ì „ì²´ ì„±ê³µë¥  ê³„ì‚° (Pandas)"""
        if not self._df_hourly:
            return 0.0
        
        df = pd.DataFrame(self._df_hourly)
        # Convert to numeric types
        df['record_count'] = pd.to_numeric(df['record_count'], errors='coerce')
        df['expected_count'] = pd.to_numeric(df['expected_count'], errors='coerce')
        
        total_records = df['record_count'].sum()
        expected_records = df['expected_count'].sum()
        
        if expected_records > 0:
            return round(float(total_records / expected_records) * 100, 2)
        return 0.0
    
    @rx.var
    def total_records(self) -> int:
        """ì „ì²´ ë ˆì½”ë“œ ìˆ˜"""
        if not self._df_hourly:
            return 0
        df = pd.DataFrame(self._df_hourly)
        df['record_count'] = pd.to_numeric(df['record_count'], errors='coerce')
        return int(df['record_count'].sum())
    
    @rx.var
    def expected_records(self) -> int:
        """ì˜ˆìƒ ë ˆì½”ë“œ ìˆ˜"""
        if not self._df_hourly:
            return 0
        df = pd.DataFrame(self._df_hourly)
        df['expected_count'] = pd.to_numeric(df['expected_count'], errors='coerce')
        return int(df['expected_count'].sum())
    
    @rx.var
    def heatmap_matrix(self) -> List[List[float]]:
        """Pandas pivot_tableë¡œ íˆíŠ¸ë§µ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
        if not self._df_hourly:
            return [[0] * 24 for _ in range(self.selected_days)]
        
        df = pd.DataFrame(self._df_hourly)
        df['success_rate'] = pd.to_numeric(df['success_rate'], errors='coerce')
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['date'] = df['timestamp'].dt.date
        df['hour'] = df['timestamp'].dt.hour
        
        # Pivot tableë¡œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        pivot = df.pivot_table(
            values='success_rate',
            index='date',
            columns='hour',
            fill_value=0,
            aggfunc='mean'  # Explicitly set aggregation function
        )
        
        # ëª¨ë“  ì‹œê°„(0-23)ì´ í¬í•¨ë˜ë„ë¡ reindex
        pivot = pivot.reindex(columns=range(24), fill_value=0)
        
        return pivot.values.tolist()
    
    @rx.var
    def hour_labels(self) -> List[str]:
        """ì‹œê°„ ë¼ë²¨ (00-23)"""
        return [f"{i:02d}" for i in range(24)]
    
    @rx.var
    def date_labels(self) -> List[str]:
        """ë‚ ì§œ ë¼ë²¨"""
        if not self._df_hourly:
            return []
        
        df = pd.DataFrame(self._df_hourly)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['date'] = df['timestamp'].dt.date
        
        dates = sorted(df['date'].unique())
        return [str(date) for date in dates]
    
    @rx.var
    def heatmap_dates(self) -> List[str]:
        """íˆíŠ¸ë§µìš© ë‚ ì§œ ë¦¬ìŠ¤íŠ¸"""
        return self.date_labels
    
    @rx.var
    def daily_chart_data(self) -> List[Dict]:
        """ì¼ë³„ íŠ¸ë Œë“œ ì°¨íŠ¸ ë°ì´í„°"""
        if not self._df_daily:
            return []
        
        df = pd.DataFrame(self._df_daily)
        df = df[df['tag_name'] == self.selected_tag].copy()
        df = df.sort_values('date')
        
        # ë‚ ì§œ í¬ë§·íŒ…
        df['date'] = pd.to_datetime(df['date']).dt.strftime('%m/%d')
        
        return df[['date', 'success_rate']].to_dict('records')
    
    @rx.var
    def hourly_pattern_stats(self) -> Dict[str, Any]:
        """ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„ (Pandas í™œìš©)"""
        if not self._df_hourly:
            return {"best_hour": "N/A", "worst_hour": "N/A", "std_dev": 0}
        
        df = pd.DataFrame(self._df_hourly)
        # Convert Decimal to float
        df['success_rate'] = df['success_rate'].astype(float)
        df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ì„±ê³µë¥ 
        hourly_avg = df.groupby('hour')['success_rate'].mean()
        
        if not hourly_avg.empty:
            best_hour = hourly_avg.idxmax()
            worst_hour = hourly_avg.idxmin()
            std_dev = float(df['success_rate'].std())  # Ensure float
            
            return {
                "best_hour": f"{best_hour:02d}:00",
                "worst_hour": f"{worst_hour:02d}:00",
                "std_dev": round(std_dev, 2) if not pd.isna(std_dev) else 0
            }
        
        return {"best_hour": "N/A", "worst_hour": "N/A", "std_dev": 0}
    
    @rx.event(background=True)
    async def set_selected_days_str(self, days: str | List[str]):
        """Segmented controlì—ì„œ ì„ íƒí•œ ì¼ìˆ˜ ì„¤ì • ë° ìë™ ìƒˆë¡œê³ ì¹¨"""
        # Segmented controlì€ ë¬¸ìì—´ì„ ë°˜í™˜
        if isinstance(days, list):
            days = days[0] if days else "7"
        
        async with self:
            try:
                self.selected_days = int(days)
            except (ValueError, TypeError):
                self.selected_days = 7
        
        # ìë™ìœ¼ë¡œ ë°ì´í„° ìƒˆë¡œê³ ì¹¨
        return CommunicationState.refresh_data
    
    @rx.event(background=True)
    async def initialize(self):
        """ì´ˆê¸°í™”"""
        async with self:
            print("ğŸ” CommunicationState.initialize() called")
            self.loading = True
            
            # íƒœê·¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            query = "SELECT DISTINCT tag_name FROM influx_latest ORDER BY tag_name"
            print(f"ğŸ” Fetching tags with query: {query}")
            result = await q(query, ())
            if result:
                self.available_tags = [row['tag_name'] for row in result]
                if not self.selected_tag and self.available_tags:
                    self.selected_tag = self.available_tags[0]
            
            print(f"ğŸ” Available tags: {self.available_tags}")
            print(f"ğŸ” Selected tag: {self.selected_tag}")
        
        # ë°ì´í„° ë¡œë“œ
        async with self:
            self.loading = False
            print("âœ… CommunicationState.initialize() completed")
        
        # Return the refresh_data event to trigger it
        return CommunicationState.refresh_data
    
    @rx.event(background=True)
    async def refresh_data(self):
        """ë°ì´í„° ìƒˆë¡œê³ ì¹¨ (Pandas ì‚¬ìš©)"""
        # Get values outside async with self context
        selected_tag = self.selected_tag
        selected_days = self.selected_days
        
        print(f"ğŸ” refresh_data() called for tag: {selected_tag}, days: {selected_days}")
        
        async with self:
            self.loading = True
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=selected_days)
        print(f"ğŸ” Date range: {start_date} to {end_date}")
        
        # ì‹œê°„ë³„ ë°ì´í„° ì¿¼ë¦¬
        query_hourly = """
        WITH hourly_data AS (
            SELECT 
                date_trunc('hour', ts) as timestamp,
                COUNT(*) as record_count,
                720 as expected_count
            FROM influx_hist
            WHERE ts >= %s AND ts < %s AND tag_name = %s
            GROUP BY date_trunc('hour', ts)
        )
        SELECT 
            timestamp,
            record_count,
            expected_count,
            ROUND((record_count::NUMERIC / expected_count) * 100, 2) as success_rate,
            TO_CHAR(timestamp, 'YYYY-MM-DD') as date,
            EXTRACT(hour FROM timestamp) as hour
        FROM hourly_data
        ORDER BY timestamp DESC
        """
        
        print(f"ğŸ” Executing hourly query for tag: {selected_tag}")
        result_hourly = await q(query_hourly, (start_date, end_date, selected_tag))
        print(f"ğŸ” Hourly query returned {len(result_hourly) if result_hourly else 0} rows")
        
        # ì¼ë³„ ë°ì´í„° ì¿¼ë¦¬
        query_daily = """
        WITH daily_data AS (
            SELECT 
                date_trunc('day', ts) as date,
                tag_name,
                COUNT(*) as daily_count,
                17280 as expected_daily_count
            FROM influx_hist
            WHERE ts >= %s AND ts < %s
            GROUP BY date_trunc('day', ts), tag_name
        )
        SELECT 
            date,
            tag_name,
            daily_count,
            expected_daily_count,
            ROUND((daily_count::NUMERIC / expected_daily_count) * 100, 2) as success_rate
        FROM daily_data
        ORDER BY date DESC
        """
        
        result_daily = await q(query_daily, (start_date, end_date))
        
        async with self:
            self._df_hourly = result_hourly if result_hourly else []
            self._df_daily = result_daily if result_daily else []
            self.loading = False
    
    @rx.event(background=True)
    async def set_selected_tag(self, tag: str):
        """íƒœê·¸ ì„ íƒ ë° ë°ì´í„° ê°±ì‹ """
        async with self:
            self.selected_tag = tag
        return CommunicationState.refresh_data
    
    @rx.var
    def anomaly_detection(self) -> List[Dict]:
        """ì´ìƒì¹˜ íƒì§€ (Z-score ì‚¬ìš©)"""
        if not self._df_hourly:
            return []
        
        df = pd.DataFrame(self._df_hourly)
        df['success_rate'] = pd.to_numeric(df['success_rate'], errors='coerce')
        
        # Z-score ê³„ì‚°
        mean = df['success_rate'].mean()
        std = df['success_rate'].std()
        
        if std > 0 and not pd.isna(std):
            df['z_score'] = np.abs((df['success_rate'] - mean) / std)
            anomalies = df[df['z_score'] > 2]  # Z-score > 2ëŠ” ì´ìƒì¹˜
            
            if not anomalies.empty:
                # Create a copy to avoid SettingWithCopyWarning
                anomalies = anomalies.copy()
                anomalies['timestamp'] = pd.to_datetime(anomalies['timestamp']).dt.strftime('%m/%d %H:%M')
                # Convert to float before rounding
                anomalies['success_rate'] = anomalies['success_rate'].astype(float)
                anomalies['z_score'] = anomalies['z_score'].astype(float)
                return anomalies[['timestamp', 'success_rate', 'z_score']].round(2).to_dict('records')
        
        return []